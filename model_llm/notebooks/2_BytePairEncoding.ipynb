{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement minbpe (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for minbpe\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q minbpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2027114"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"model_llm/data/feynman_combined_text.txt\", \"r\") as f:\n",
    "    text_sequence = f.read()\n",
    "\n",
    "len(text_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using the [minBPE](https://github.com/karpathy/minbpe) repository to tokenize the sequence of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by training the tokenizer on the text sequence that you saved in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/768 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 768/768 [04:55<00:00,  2.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from model_llm.minbpe import BasicTokenizer\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.train(text_sequence, vocab_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: b'\\x00',\n",
       " 1: b'\\x01',\n",
       " 2: b'\\x02',\n",
       " 3: b'\\x03',\n",
       " 4: b'\\x04',\n",
       " 5: b'\\x05',\n",
       " 6: b'\\x06',\n",
       " 7: b'\\x07',\n",
       " 8: b'\\x08',\n",
       " 9: b'\\t',\n",
       " 10: b'\\n',\n",
       " 11: b'\\x0b',\n",
       " 12: b'\\x0c',\n",
       " 13: b'\\r',\n",
       " 14: b'\\x0e',\n",
       " 15: b'\\x0f',\n",
       " 16: b'\\x10',\n",
       " 17: b'\\x11',\n",
       " 18: b'\\x12',\n",
       " 19: b'\\x13',\n",
       " 20: b'\\x14',\n",
       " 21: b'\\x15',\n",
       " 22: b'\\x16',\n",
       " 23: b'\\x17',\n",
       " 24: b'\\x18',\n",
       " 25: b'\\x19',\n",
       " 26: b'\\x1a',\n",
       " 27: b'\\x1b',\n",
       " 28: b'\\x1c',\n",
       " 29: b'\\x1d',\n",
       " 30: b'\\x1e',\n",
       " 31: b'\\x1f',\n",
       " 32: b' ',\n",
       " 33: b'!',\n",
       " 34: b'\"',\n",
       " 35: b'#',\n",
       " 36: b'$',\n",
       " 37: b'%',\n",
       " 38: b'&',\n",
       " 39: b\"'\",\n",
       " 40: b'(',\n",
       " 41: b')',\n",
       " 42: b'*',\n",
       " 43: b'+',\n",
       " 44: b',',\n",
       " 45: b'-',\n",
       " 46: b'.',\n",
       " 47: b'/',\n",
       " 48: b'0',\n",
       " 49: b'1',\n",
       " 50: b'2',\n",
       " 51: b'3',\n",
       " 52: b'4',\n",
       " 53: b'5',\n",
       " 54: b'6',\n",
       " 55: b'7',\n",
       " 56: b'8',\n",
       " 57: b'9',\n",
       " 58: b':',\n",
       " 59: b';',\n",
       " 60: b'<',\n",
       " 61: b'=',\n",
       " 62: b'>',\n",
       " 63: b'?',\n",
       " 64: b'@',\n",
       " 65: b'A',\n",
       " 66: b'B',\n",
       " 67: b'C',\n",
       " 68: b'D',\n",
       " 69: b'E',\n",
       " 70: b'F',\n",
       " 71: b'G',\n",
       " 72: b'H',\n",
       " 73: b'I',\n",
       " 74: b'J',\n",
       " 75: b'K',\n",
       " 76: b'L',\n",
       " 77: b'M',\n",
       " 78: b'N',\n",
       " 79: b'O',\n",
       " 80: b'P',\n",
       " 81: b'Q',\n",
       " 82: b'R',\n",
       " 83: b'S',\n",
       " 84: b'T',\n",
       " 85: b'U',\n",
       " 86: b'V',\n",
       " 87: b'W',\n",
       " 88: b'X',\n",
       " 89: b'Y',\n",
       " 90: b'Z',\n",
       " 91: b'[',\n",
       " 92: b'\\\\',\n",
       " 93: b']',\n",
       " 94: b'^',\n",
       " 95: b'_',\n",
       " 96: b'`',\n",
       " 97: b'a',\n",
       " 98: b'b',\n",
       " 99: b'c',\n",
       " 100: b'd',\n",
       " 101: b'e',\n",
       " 102: b'f',\n",
       " 103: b'g',\n",
       " 104: b'h',\n",
       " 105: b'i',\n",
       " 106: b'j',\n",
       " 107: b'k',\n",
       " 108: b'l',\n",
       " 109: b'm',\n",
       " 110: b'n',\n",
       " 111: b'o',\n",
       " 112: b'p',\n",
       " 113: b'q',\n",
       " 114: b'r',\n",
       " 115: b's',\n",
       " 116: b't',\n",
       " 117: b'u',\n",
       " 118: b'v',\n",
       " 119: b'w',\n",
       " 120: b'x',\n",
       " 121: b'y',\n",
       " 122: b'z',\n",
       " 123: b'{',\n",
       " 124: b'|',\n",
       " 125: b'}',\n",
       " 126: b'~',\n",
       " 127: b'\\x7f',\n",
       " 128: b'\\x80',\n",
       " 129: b'\\x81',\n",
       " 130: b'\\x82',\n",
       " 131: b'\\x83',\n",
       " 132: b'\\x84',\n",
       " 133: b'\\x85',\n",
       " 134: b'\\x86',\n",
       " 135: b'\\x87',\n",
       " 136: b'\\x88',\n",
       " 137: b'\\x89',\n",
       " 138: b'\\x8a',\n",
       " 139: b'\\x8b',\n",
       " 140: b'\\x8c',\n",
       " 141: b'\\x8d',\n",
       " 142: b'\\x8e',\n",
       " 143: b'\\x8f',\n",
       " 144: b'\\x90',\n",
       " 145: b'\\x91',\n",
       " 146: b'\\x92',\n",
       " 147: b'\\x93',\n",
       " 148: b'\\x94',\n",
       " 149: b'\\x95',\n",
       " 150: b'\\x96',\n",
       " 151: b'\\x97',\n",
       " 152: b'\\x98',\n",
       " 153: b'\\x99',\n",
       " 154: b'\\x9a',\n",
       " 155: b'\\x9b',\n",
       " 156: b'\\x9c',\n",
       " 157: b'\\x9d',\n",
       " 158: b'\\x9e',\n",
       " 159: b'\\x9f',\n",
       " 160: b'\\xa0',\n",
       " 161: b'\\xa1',\n",
       " 162: b'\\xa2',\n",
       " 163: b'\\xa3',\n",
       " 164: b'\\xa4',\n",
       " 165: b'\\xa5',\n",
       " 166: b'\\xa6',\n",
       " 167: b'\\xa7',\n",
       " 168: b'\\xa8',\n",
       " 169: b'\\xa9',\n",
       " 170: b'\\xaa',\n",
       " 171: b'\\xab',\n",
       " 172: b'\\xac',\n",
       " 173: b'\\xad',\n",
       " 174: b'\\xae',\n",
       " 175: b'\\xaf',\n",
       " 176: b'\\xb0',\n",
       " 177: b'\\xb1',\n",
       " 178: b'\\xb2',\n",
       " 179: b'\\xb3',\n",
       " 180: b'\\xb4',\n",
       " 181: b'\\xb5',\n",
       " 182: b'\\xb6',\n",
       " 183: b'\\xb7',\n",
       " 184: b'\\xb8',\n",
       " 185: b'\\xb9',\n",
       " 186: b'\\xba',\n",
       " 187: b'\\xbb',\n",
       " 188: b'\\xbc',\n",
       " 189: b'\\xbd',\n",
       " 190: b'\\xbe',\n",
       " 191: b'\\xbf',\n",
       " 192: b'\\xc0',\n",
       " 193: b'\\xc1',\n",
       " 194: b'\\xc2',\n",
       " 195: b'\\xc3',\n",
       " 196: b'\\xc4',\n",
       " 197: b'\\xc5',\n",
       " 198: b'\\xc6',\n",
       " 199: b'\\xc7',\n",
       " 200: b'\\xc8',\n",
       " 201: b'\\xc9',\n",
       " 202: b'\\xca',\n",
       " 203: b'\\xcb',\n",
       " 204: b'\\xcc',\n",
       " 205: b'\\xcd',\n",
       " 206: b'\\xce',\n",
       " 207: b'\\xcf',\n",
       " 208: b'\\xd0',\n",
       " 209: b'\\xd1',\n",
       " 210: b'\\xd2',\n",
       " 211: b'\\xd3',\n",
       " 212: b'\\xd4',\n",
       " 213: b'\\xd5',\n",
       " 214: b'\\xd6',\n",
       " 215: b'\\xd7',\n",
       " 216: b'\\xd8',\n",
       " 217: b'\\xd9',\n",
       " 218: b'\\xda',\n",
       " 219: b'\\xdb',\n",
       " 220: b'\\xdc',\n",
       " 221: b'\\xdd',\n",
       " 222: b'\\xde',\n",
       " 223: b'\\xdf',\n",
       " 224: b'\\xe0',\n",
       " 225: b'\\xe1',\n",
       " 226: b'\\xe2',\n",
       " 227: b'\\xe3',\n",
       " 228: b'\\xe4',\n",
       " 229: b'\\xe5',\n",
       " 230: b'\\xe6',\n",
       " 231: b'\\xe7',\n",
       " 232: b'\\xe8',\n",
       " 233: b'\\xe9',\n",
       " 234: b'\\xea',\n",
       " 235: b'\\xeb',\n",
       " 236: b'\\xec',\n",
       " 237: b'\\xed',\n",
       " 238: b'\\xee',\n",
       " 239: b'\\xef',\n",
       " 240: b'\\xf0',\n",
       " 241: b'\\xf1',\n",
       " 242: b'\\xf2',\n",
       " 243: b'\\xf3',\n",
       " 244: b'\\xf4',\n",
       " 245: b'\\xf5',\n",
       " 246: b'\\xf6',\n",
       " 247: b'\\xf7',\n",
       " 248: b'\\xf8',\n",
       " 249: b'\\xf9',\n",
       " 250: b'\\xfa',\n",
       " 251: b'\\xfb',\n",
       " 252: b'\\xfc',\n",
       " 253: b'\\xfd',\n",
       " 254: b'\\xfe',\n",
       " 255: b'\\xff',\n",
       " 256: b'e ',\n",
       " 257: b'th',\n",
       " 258: b' th',\n",
       " 259: b's ',\n",
       " 260: b'in',\n",
       " 261: b't ',\n",
       " 262: b'er',\n",
       " 263: b'an',\n",
       " 264: b'on',\n",
       " 265: b' the ',\n",
       " 266: b', ',\n",
       " 267: b'en',\n",
       " 268: b'at',\n",
       " 269: b'd ',\n",
       " 270: b'or',\n",
       " 271: b'of',\n",
       " 272: b'al',\n",
       " 273: b'ar',\n",
       " 274: b'y ',\n",
       " 275: b're',\n",
       " 276: b'. ',\n",
       " 277: b'ti',\n",
       " 278: b'is ',\n",
       " 279: b'ou',\n",
       " 280: b'o ',\n",
       " 281: b'le',\n",
       " 282: b'a ',\n",
       " 283: b'ing',\n",
       " 284: b'\\xc2\\xa0',\n",
       " 285: b'is',\n",
       " 286: b'ch',\n",
       " 287: b'we ',\n",
       " 288: b'of ',\n",
       " 289: b'om',\n",
       " 290: b'at ',\n",
       " 291: b'e\\n',\n",
       " 292: b'\\xe2\\x80',\n",
       " 293: b'\\xe2\\x88',\n",
       " 294: b'as',\n",
       " 295: b'on ',\n",
       " 296: b'wh',\n",
       " 297: b'es',\n",
       " 298: b'it',\n",
       " 299: b'er ',\n",
       " 300: b'ow',\n",
       " 301: b'ing ',\n",
       " 302: b'to ',\n",
       " 303: b'for',\n",
       " 304: b'and ',\n",
       " 305: b'el',\n",
       " 306: b'av',\n",
       " 307: b'in ',\n",
       " 308: b'st',\n",
       " 309: b'ct',\n",
       " 310: b'e th',\n",
       " 311: b'si',\n",
       " 312: b'\\xe2\\x88\\x92',\n",
       " 313: b'es ',\n",
       " 314: b'Th',\n",
       " 315: b'ed ',\n",
       " 316: b'ati',\n",
       " 317: b'ig',\n",
       " 318: b'us',\n",
       " 319: b'it ',\n",
       " 320: b'di',\n",
       " 321: b'all',\n",
       " 322: b'al ',\n",
       " 323: b'an ',\n",
       " 324: b'.\\n',\n",
       " 325: b'os',\n",
       " 326: b'wi',\n",
       " 327: b'to',\n",
       " 328: b'qu',\n",
       " 329: b'ch ',\n",
       " 330: b'll',\n",
       " 331: b'um',\n",
       " 332: b'of the ',\n",
       " 333: b'no',\n",
       " 334: b'and',\n",
       " 335: b'ec',\n",
       " 336: b'ro',\n",
       " 337: b'am',\n",
       " 338: b'en ',\n",
       " 339: b' that ',\n",
       " 340: b'ic',\n",
       " 341: b'ur',\n",
       " 342: b'pl',\n",
       " 343: b'ent',\n",
       " 344: b'as ',\n",
       " 345: b'ac',\n",
       " 346: b' the\\n',\n",
       " 347: b'ul',\n",
       " 348: b'ver',\n",
       " 349: b'are ',\n",
       " 350: b'ma',\n",
       " 351: b'. Th',\n",
       " 352: b'ex',\n",
       " 353: b'hav',\n",
       " 354: b'igh',\n",
       " 355: b'whi',\n",
       " 356: b'ed',\n",
       " 357: b'em',\n",
       " 358: b'\\xcf\\x89',\n",
       " 359: b'e, ',\n",
       " 360: b'mo',\n",
       " 361: b'ere ',\n",
       " 362: b'f ',\n",
       " 363: b'ab',\n",
       " 364: b'ol',\n",
       " 365: b'our',\n",
       " 366: b'\\nth',\n",
       " 367: b'tion',\n",
       " 368: b'be ',\n",
       " 369: b'res',\n",
       " 370: b'con',\n",
       " 371: b'pro',\n",
       " 372: b'et',\n",
       " 373: b'sh',\n",
       " 374: b'fr',\n",
       " 375: b'tion ',\n",
       " 376: b'not ',\n",
       " 377: b'e the ',\n",
       " 378: b'which ',\n",
       " 379: b'with',\n",
       " 380: b'oth',\n",
       " 381: b'have ',\n",
       " 382: b' the s',\n",
       " 383: b'ce ',\n",
       " 384: b'ap',\n",
       " 385: b'ly ',\n",
       " 386: b's, ',\n",
       " 387: b'tic',\n",
       " 388: b'. I',\n",
       " 389: b'or ',\n",
       " 390: b'com',\n",
       " 391: b'un',\n",
       " 392: b'ir',\n",
       " 393: b'ow ',\n",
       " 394: b'ter',\n",
       " 395: b' that',\n",
       " 396: b'me',\n",
       " 397: b'ation',\n",
       " 398: b'ay',\n",
       " 399: b',\\n',\n",
       " 400: b'ent ',\n",
       " 401: b'ener',\n",
       " 402: b'tr',\n",
       " 403: b'dis',\n",
       " 404: b'par',\n",
       " 405: b'ff',\n",
       " 406: b'le ',\n",
       " 407: b'se',\n",
       " 408: b'one ',\n",
       " 409: b'can ',\n",
       " 410: b'per',\n",
       " 411: b'from',\n",
       " 412: b'ang',\n",
       " 413: b'oul',\n",
       " 414: b'bu',\n",
       " 415: b'de',\n",
       " 416: b'ation ',\n",
       " 417: b'\\xe2\\x80\\x93',\n",
       " 418: b'ta',\n",
       " 419: b'n ',\n",
       " 420: b'su',\n",
       " 421: b'll ',\n",
       " 422: b'ect',\n",
       " 423: b'oc',\n",
       " 424: b' this ',\n",
       " 425: b'ould ',\n",
       " 426: b'li',\n",
       " 427: b'all ',\n",
       " 428: b'tim',\n",
       " 429: b'\\xe2\\x80\\xb2',\n",
       " 430: b'ight ',\n",
       " 431: b'ne',\n",
       " 432: b'po',\n",
       " 433: b', and ',\n",
       " 434: b'\\xce\\x94',\n",
       " 435: b'ag',\n",
       " 436: b'fin',\n",
       " 437: b'ph',\n",
       " 438: b'ad',\n",
       " 439: b'be',\n",
       " 440: b'energ',\n",
       " 441: b'ar ',\n",
       " 442: b'lect',\n",
       " 443: b'in the ',\n",
       " 444: b'\\nthe ',\n",
       " 445: b'ci',\n",
       " 446: b'som',\n",
       " 447: b'. W',\n",
       " 448: b'equ',\n",
       " 449: b'for ',\n",
       " 450: b'oun',\n",
       " 451: b'k ',\n",
       " 452: b', the ',\n",
       " 453: b'im',\n",
       " 454: b'by ',\n",
       " 455: b'00',\n",
       " 456: b'y\\n',\n",
       " 457: b'act',\n",
       " 458: b'our ',\n",
       " 459: b'if ',\n",
       " 460: b'other ',\n",
       " 461: b'iv',\n",
       " 462: b'so ',\n",
       " 463: b'with ',\n",
       " 464: b'us ',\n",
       " 465: b'will ',\n",
       " 466: b'rec',\n",
       " 467: b'sp',\n",
       " 468: b'.1',\n",
       " 469: b'\\xe2\\x80\\x9c',\n",
       " 470: b'\\xe2\\x80\\x9d',\n",
       " 471: b'to the ',\n",
       " 472: b'cal',\n",
       " 473: b'diff',\n",
       " 474: b'aw',\n",
       " 475: b'fi',\n",
       " 476: b'ple',\n",
       " 477: b', we ',\n",
       " 478: b'gh',\n",
       " 479: b')(',\n",
       " 480: b'The ',\n",
       " 481: b'wav',\n",
       " 482: b') ',\n",
       " 483: b'ob',\n",
       " 484: b'tw',\n",
       " 485: b'vel',\n",
       " 486: b'is\\n',\n",
       " 487: b'pos',\n",
       " 488: b', th',\n",
       " 489: b'ust ',\n",
       " 490: b'a\\n',\n",
       " 491: b'but ',\n",
       " 492: b'aus',\n",
       " 493: b'ough',\n",
       " 494: b'e of ',\n",
       " 495: b'co',\n",
       " 496: b'anc',\n",
       " 497: b'go',\n",
       " 498: b'. The ',\n",
       " 499: b'ge',\n",
       " 500: b'ke ',\n",
       " 501: b'bec',\n",
       " 502: b'differ',\n",
       " 503: b'out',\n",
       " 504: b'ri',\n",
       " 505: b'it is ',\n",
       " 506: b'so',\n",
       " 507: b'lectr',\n",
       " 508: b'form',\n",
       " 509: b'up',\n",
       " 510: b'ity ',\n",
       " 511: b'ight',\n",
       " 512: b'\\xe2\\x88\\x92\\xe2\\x88\\x92',\n",
       " 513: b'wor',\n",
       " 514: b's of ',\n",
       " 515: b'ame ',\n",
       " 516: b'very ',\n",
       " 517: b'electr',\n",
       " 518: b'ure',\n",
       " 519: b'lo',\n",
       " 520: b'kn',\n",
       " 521: b've ',\n",
       " 522: b'il',\n",
       " 523: b'. S',\n",
       " 524: b's\\n',\n",
       " 525: b'der',\n",
       " 526: b'0.',\n",
       " 527: b'cl',\n",
       " 528: b' the',\n",
       " 529: b'Fig',\n",
       " 530: b'int',\n",
       " 531: b'becaus',\n",
       " 532: b'num',\n",
       " 533: b'um ',\n",
       " 534: b'\\xe2\\x80\\x9d ',\n",
       " 535: b'any ',\n",
       " 536: b'would ',\n",
       " 537: b'partic',\n",
       " 538: b'out ',\n",
       " 539: b'dt',\n",
       " 540: b'y, ',\n",
       " 541: b'ra',\n",
       " 542: b'\\xce\\xb8',\n",
       " 543: b'pen',\n",
       " 544: b'from ',\n",
       " 545: b'do',\n",
       " 546: b'two ',\n",
       " 547: b'ea',\n",
       " 548: b'of\\n',\n",
       " 549: b'ut',\n",
       " 550: b'at the ',\n",
       " 551: b'numb',\n",
       " 552: b'pres',\n",
       " 553: b'is the ',\n",
       " 554: b' that the ',\n",
       " 555: b'veloc',\n",
       " 556: b'. We ',\n",
       " 557: b'dist',\n",
       " 558: b'.\\xc2\\xa0',\n",
       " 559: b'energy ',\n",
       " 560: b'mor',\n",
       " 561: b'ure ',\n",
       " 562: b'inter',\n",
       " 563: b'ong',\n",
       " 564: b'arg',\n",
       " 565: b'law',\n",
       " 566: b'we have ',\n",
       " 567: b'ant',\n",
       " 568: b'by',\n",
       " 569: b'ate ',\n",
       " 570: b'you',\n",
       " 571: b'12',\n",
       " 572: b'vi',\n",
       " 573: b' is ',\n",
       " 574: b'if',\n",
       " 575: b', and',\n",
       " 576: b' there ',\n",
       " 577: b'10',\n",
       " 578: b'ay ',\n",
       " 579: b'gr',\n",
       " 580: b'enc',\n",
       " 581: b'e that ',\n",
       " 582: b'les ',\n",
       " 583: b'atom',\n",
       " 584: b'some ',\n",
       " 585: b'has ',\n",
       " 586: b'sin',\n",
       " 587: b'we',\n",
       " 588: b'what ',\n",
       " 589: b'chang',\n",
       " 590: b'\\xe2\\x80\\x94',\n",
       " 591: b'ally ',\n",
       " 592: b'only ',\n",
       " 593: b'sic',\n",
       " 594: b'ari',\n",
       " 595: b'br',\n",
       " 596: b'cos',\n",
       " 597: b'lec',\n",
       " 598: b'forc',\n",
       " 599: b'cur',\n",
       " 600: b'direc',\n",
       " 601: b'you ',\n",
       " 602: b'way',\n",
       " 603: b'; ',\n",
       " 604: b'fiel',\n",
       " 605: b'in a ',\n",
       " 606: b'du',\n",
       " 607: b'do ',\n",
       " 608: b'1.',\n",
       " 609: b'ear',\n",
       " 610: b'str',\n",
       " 611: b'2)',\n",
       " 612: b'mov',\n",
       " 613: b'prob',\n",
       " 614: b'ord',\n",
       " 615: b'mas',\n",
       " 616: b'mom',\n",
       " 617: b'know',\n",
       " 618: b'? ',\n",
       " 619: b'de ',\n",
       " 620: b'sy',\n",
       " 621: b'light ',\n",
       " 622: b'ect ',\n",
       " 623: b'ic ',\n",
       " 624: b'op',\n",
       " 625: b'ell',\n",
       " 626: b': ',\n",
       " 627: b'requ',\n",
       " 628: b'pon',\n",
       " 629: b'ere',\n",
       " 630: b'. A',\n",
       " 631: b'sim',\n",
       " 632: b'if we ',\n",
       " 633: b'giv',\n",
       " 634: b'cer',\n",
       " 635: b'is a ',\n",
       " 636: b'ther ',\n",
       " 637: b'not',\n",
       " 638: b' the same ',\n",
       " 639: b'he',\n",
       " 640: b'ance ',\n",
       " 641: b'may ',\n",
       " 642: b', but ',\n",
       " 643: b'ysic',\n",
       " 644: b'kin',\n",
       " 645: b'.(',\n",
       " 646: b'e\\xc2\\xa0',\n",
       " 647: b'lin',\n",
       " 648: b'ey',\n",
       " 649: b'more ',\n",
       " 650: b'ess',\n",
       " 651: b'we\\n',\n",
       " 652: b'rel',\n",
       " 653: b'ase ',\n",
       " 654: b'ser',\n",
       " 655: b'tur',\n",
       " 656: b'and\\xc2\\xa0',\n",
       " 657: b'ity',\n",
       " 658: b'other',\n",
       " 659: b'les',\n",
       " 660: b'molec',\n",
       " 661: b'on the ',\n",
       " 662: b'certa',\n",
       " 663: b'can',\n",
       " 664: b'must ',\n",
       " 665: b'ated ',\n",
       " 666: b'. If ',\n",
       " 667: b'ter ',\n",
       " 668: b'ing the ',\n",
       " 669: b'time ',\n",
       " 670: b'mu',\n",
       " 671: b'cill',\n",
       " 672: b'oscill',\n",
       " 673: b'moment',\n",
       " 674: b'obj',\n",
       " 675: b'por',\n",
       " 676: b'eng',\n",
       " 677: b'\\xcf\\x80',\n",
       " 678: b'was ',\n",
       " 679: b'ei',\n",
       " 680: b'bet',\n",
       " 681: b'sib',\n",
       " 682: b'em ',\n",
       " 683: b'itt',\n",
       " 684: b'in\\n',\n",
       " 685: b'ax',\n",
       " 686: b'ular ',\n",
       " 687: b't of ',\n",
       " 688: b'ans',\n",
       " 689: b'force ',\n",
       " 690: b'ours',\n",
       " 691: b'enti',\n",
       " 692: b'ly',\n",
       " 693: b'vol',\n",
       " 694: b'say',\n",
       " 695: b'tion of ',\n",
       " 696: b'\\xe2\\x81',\n",
       " 697: b'\\xe2\\x81\\xa1',\n",
       " 698: b't us ',\n",
       " 699: b'frequ',\n",
       " 700: b'ew',\n",
       " 701: b'when ',\n",
       " 702: b'ite ',\n",
       " 703: b'no ',\n",
       " 704: b'We ',\n",
       " 705: b'\\xe2\\x8b',\n",
       " 706: b'fact',\n",
       " 707: b'ist',\n",
       " 708: b't is ',\n",
       " 709: b'lem',\n",
       " 710: b'd\\n',\n",
       " 711: b'perat',\n",
       " 712: b'because ',\n",
       " 713: b'ese ',\n",
       " 714: b'sol',\n",
       " 715: b'ens',\n",
       " 716: b'to\\n',\n",
       " 717: b'\\xce\\xb3',\n",
       " 718: b'kT',\n",
       " 719: b'Fig.\\xc2\\xa0',\n",
       " 720: b'from the ',\n",
       " 721: b'shall ',\n",
       " 722: b'we can ',\n",
       " 723: b' they ',\n",
       " 724: b'xx',\n",
       " 725: b'ud',\n",
       " 726: b'rough',\n",
       " 727: b'en the ',\n",
       " 728: b'fir',\n",
       " 729: b'how ',\n",
       " 730: b'\\xcf\\x890',\n",
       " 731: b')=',\n",
       " 732: b'some',\n",
       " 733: b'\\xe2\\x80\\x99',\n",
       " 734: b'. B',\n",
       " 735: b'cle',\n",
       " 736: b'just ',\n",
       " 737: b'its ',\n",
       " 738: b'th ',\n",
       " 739: b'different ',\n",
       " 740: b'ot',\n",
       " 741: b'Now ',\n",
       " 742: b'ely ',\n",
       " 743: b'betwe',\n",
       " 744: b'ev',\n",
       " 745: b'\\xe2\\x88\\x82',\n",
       " 746: b'posi',\n",
       " 747: b'ever',\n",
       " 748: b'ant ',\n",
       " 749: b'const',\n",
       " 750: b'al\\n',\n",
       " 751: b'hap',\n",
       " 752: b'/2',\n",
       " 753: b'light',\n",
       " 754: b'calle',\n",
       " 755: b'/dt',\n",
       " 756: b'ut ',\n",
       " 757: b'number ',\n",
       " 758: b'/c',\n",
       " 759: b'min',\n",
       " 760: b'cri',\n",
       " 761: b'ep',\n",
       " 762: b'exam',\n",
       " 763: b'tic ',\n",
       " 764: b'ons ',\n",
       " 765: b'reas',\n",
       " 766: b'show',\n",
       " 767: b'mag',\n",
       " 768: b'tem',\n",
       " 769: b'and the ',\n",
       " 770: b'sec',\n",
       " 771: b'ical ',\n",
       " 772: b'of the\\n',\n",
       " 773: b'gre',\n",
       " 774: b'ther',\n",
       " 775: b'\\xe2\\x8b\\x85',\n",
       " 776: b'es, ',\n",
       " 777: b'each ',\n",
       " 778: b'thing ',\n",
       " 779: b'st ',\n",
       " 780: b'radi',\n",
       " 781: b'pre',\n",
       " 782: b'also ',\n",
       " 783: b'ound ',\n",
       " 784: b'. In ',\n",
       " 785: b'est',\n",
       " 786: b'get ',\n",
       " 787: b'sti',\n",
       " 788: b'ence ',\n",
       " 789: b'id',\n",
       " 790: b'loo',\n",
       " 791: b'find',\n",
       " 792: b'1\\xe2\\x88\\x92',\n",
       " 793: b'\\xe2\\x9f',\n",
       " 794: b'sm',\n",
       " 795: b'can be ',\n",
       " 796: b'were ',\n",
       " 797: b'does ',\n",
       " 798: b'temperat',\n",
       " 799: b'problem',\n",
       " 800: b'acc',\n",
       " 801: b'ing\\n',\n",
       " 802: b'of\\xc2\\xa0',\n",
       " 803: b'es\\n',\n",
       " 804: b':\\n',\n",
       " 805: b'cours',\n",
       " 806: b'pr',\n",
       " 807: b'resul',\n",
       " 808: b'eff',\n",
       " 809: b'bo',\n",
       " 810: b'molecu',\n",
       " 811: b'make ',\n",
       " 812: b'plac',\n",
       " 813: b'charg',\n",
       " 814: b'syst',\n",
       " 815: b'. This ',\n",
       " 816: b'gener',\n",
       " 817: b'which',\n",
       " 818: b'distanc',\n",
       " 819: b'physic',\n",
       " 820: b'det',\n",
       " 821: b'time',\n",
       " 822: b'ose ',\n",
       " 823: b'erefor',\n",
       " 824: b'plan',\n",
       " 825: b'vect',\n",
       " 826: b'\\xcf\\xb5',\n",
       " 827: b' of ',\n",
       " 828: b'wr',\n",
       " 829: b'ound',\n",
       " 830: b'to\\xc2\\xa0',\n",
       " 831: b's are ',\n",
       " 832: b'brow',\n",
       " 833: b'te',\n",
       " 834: b'serv',\n",
       " 835: b'where ',\n",
       " 836: b'way ',\n",
       " 837: b'es the ',\n",
       " 838: b'your ',\n",
       " 839: b'(t',\n",
       " 840: b'anal',\n",
       " 841: b'. Wh',\n",
       " 842: b'sion',\n",
       " 843: b'with the ',\n",
       " 844: b'such ',\n",
       " 845: b'sion ',\n",
       " 846: b'cor',\n",
       " 847: b'ater',\n",
       " 848: b'cir',\n",
       " 849: b'get',\n",
       " 850: b'but',\n",
       " 851: b'is\\xc2\\xa0',\n",
       " 852: b'. O',\n",
       " 853: b'. F',\n",
       " 854: b'.\\nI',\n",
       " 855: b'about',\n",
       " 856: b'pe',\n",
       " 857: b'for the ',\n",
       " 858: b'2+',\n",
       " 859: b'frequenc',\n",
       " 860: b'\\xc2\\xaf',\n",
       " 861: b')\\n',\n",
       " 862: b'possib',\n",
       " 863: b'meas',\n",
       " 864: b'fun',\n",
       " 865: b'11',\n",
       " 866: b'20',\n",
       " 867: b'defin',\n",
       " 868: b'another ',\n",
       " 869: b'\\xcf\\x89t',\n",
       " 870: b'.\\nTh',\n",
       " 871: b'to be ',\n",
       " 872: b'certain ',\n",
       " 873: b'simpl',\n",
       " 874: b'all the ',\n",
       " 875: b'go ',\n",
       " 876: b'direction',\n",
       " 877: b'sid',\n",
       " 878: b'2=',\n",
       " 879: b'under',\n",
       " 880: b'ass',\n",
       " 881: b'a l',\n",
       " 882: b'by the ',\n",
       " 883: b'1/',\n",
       " 884: b'field ',\n",
       " 885: b'number',\n",
       " 886: b'.\\nThe ',\n",
       " 887: b', which ',\n",
       " 888: b'ary ',\n",
       " 889: b'aga',\n",
       " 890: b'of th',\n",
       " 891: b'arr',\n",
       " 892: b'equal ',\n",
       " 893: b'sup',\n",
       " 894: b'star',\n",
       " 895: b'x=',\n",
       " 896: b'isi',\n",
       " 897: b'oscillat',\n",
       " 898: b'\\xe2\\x88\\x92\\xe2\\x88\\x92\\xe2\\x88\\x92\\xe2\\x88\\x92',\n",
       " 899: b'first ',\n",
       " 900: b'ous ',\n",
       " 901: b'inst',\n",
       " 902: b'chan',\n",
       " 903: b'point',\n",
       " 904: b' and ',\n",
       " 905: b'nm',\n",
       " 906: b'(x',\n",
       " 907: b'spe',\n",
       " 908: b'Fig. ',\n",
       " 909: b'col',\n",
       " 910: b'now ',\n",
       " 911: b'ed\\n',\n",
       " 912: b'dow',\n",
       " 913: b'as the ',\n",
       " 914: b'going ',\n",
       " 915: b'much ',\n",
       " 916: b'energy',\n",
       " 917: b'cul',\n",
       " 918: b'fo',\n",
       " 919: b'ide',\n",
       " 920: b'pi',\n",
       " 921: b'comple',\n",
       " 922: b'e\\xe2\\x88\\x92',\n",
       " 923: b'vari',\n",
       " 924: b'\\xe2\\x88\\x920.',\n",
       " 925: b' through',\n",
       " 926: b'tak',\n",
       " 927: b's, and ',\n",
       " 928: b'and\\n',\n",
       " 929: b'pend',\n",
       " 930: b'wave ',\n",
       " 931: b'is, ',\n",
       " 932: b'ser ',\n",
       " 933: b'ey ',\n",
       " 934: b'able ',\n",
       " 935: b'formul',\n",
       " 936: b'\\xcf\\x84',\n",
       " 937: b'eynm',\n",
       " 938: b'are\\n',\n",
       " 939: b'v2',\n",
       " 940: b'your brow',\n",
       " 941: b'ong ',\n",
       " 942: b'interest',\n",
       " 943: b'at\\n',\n",
       " 944: b' and\\xc2\\xa0',\n",
       " 945: b'\\xcf\\x95',\n",
       " 946: b'given ',\n",
       " 947: b'bac',\n",
       " 948: b'of a ',\n",
       " 949: b'\\xe2\\x80\\x99s ',\n",
       " 950: b'. So',\n",
       " 951: b'ard',\n",
       " 952: b'motion',\n",
       " 953: b'mechan',\n",
       " 954: b'velocity ',\n",
       " 955: b'exper',\n",
       " 956: b'inci',\n",
       " 957: b'motion ',\n",
       " 958: b'plic',\n",
       " 959: b'low',\n",
       " 960: b'ov',\n",
       " 961: b'produ',\n",
       " 962: b'iz',\n",
       " 963: b'itu',\n",
       " 964: b', then ',\n",
       " 965: b'new',\n",
       " 966: b'as\\n',\n",
       " 967: b'cas',\n",
       " 968: b'des',\n",
       " 969: b'sub',\n",
       " 970: b'underst',\n",
       " 971: b'cent',\n",
       " 972: b'22',\n",
       " 973: b'ed to ',\n",
       " 974: b'work',\n",
       " 975: b'ree ',\n",
       " 976: b'at\\xc2\\xa0',\n",
       " 977: b'age ',\n",
       " 978: b'right ',\n",
       " 979: b'foll',\n",
       " 980: b'e, and ',\n",
       " 981: b'air',\n",
       " 982: b'disc',\n",
       " 983: b'equation',\n",
       " 984: b'x\\xe2\\x80\\xb2',\n",
       " 985: b'term',\n",
       " 986: b'\\xcf\\x81',\n",
       " 987: b'atter',\n",
       " 988: b's of the ',\n",
       " 989: b'ed by ',\n",
       " 990: b'eas',\n",
       " 991: b'example',\n",
       " 992: b'\\xc2\\xaf\\xc2\\xaf',\n",
       " 993: b'lik',\n",
       " 994: b'see ',\n",
       " 995: b'work ',\n",
       " 996: b'turn',\n",
       " 997: b'propor',\n",
       " 998: b'circ',\n",
       " 999: b'e\\nth',\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[345, 367, 45, 275, 345, 375, 1023, 343]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"action-reaction experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action-reaction experiment'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([345, 367, 45, 275, 345, 375, 1023, 343])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add special tokens to the vocabulary. These tokens are going to be used a lot in the fine-tuning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_id = list(tokenizer.vocab.keys())[-1]\n",
    "tokenizer.special_tokens = {\n",
    "    \"<|startoftext|>\": max_vocab_id + 1,\n",
    "    \"<|separator|>\": max_vocab_id + 2,\n",
    "    \"<|endoftext|>\": max_vocab_id + 3,\n",
    "    \"<|unk|>\": max_vocab_id + 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have more than 618K tokens for training and validation. This is pretty good, but if you can add more, that would be even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_sequence\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/model_llm/minbpe/basic.py:89\u001b[0m, in \u001b[0;36mBasicTokenizer.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     86\u001b[0m ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(text_bytes)  \u001b[38;5;66;03m# list of integers in range 0..255\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# find the pair with the lowest merge index\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43mget_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(stats, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m p: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerges\u001b[38;5;241m.\u001b[39mget(p, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# subtle: if there are no more merges available, the key will\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# result in an inf for every single pair, and the min will be\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# just the first pair in the list, arbitrarily\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# we can detect this terminating case by a membership check\u001b[39;00m\n",
      "File \u001b[0;32m~/model_llm/minbpe/base.py:22\u001b[0m, in \u001b[0;36mget_stats\u001b[0;34m(ids, counts)\u001b[0m\n\u001b[1;32m     20\u001b[0m counts \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m counts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m counts\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids, ids[\u001b[38;5;241m1\u001b[39m:]):  \u001b[38;5;66;03m# iterate consecutive elements\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     counts[pair] \u001b[38;5;241m=\u001b[39m \u001b[43mcounts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m counts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len(tokenizer.encode(text_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total tokens: 823008\n"
     ]
    }
   ],
   "source": [
    "# Sample first 100k characters to estimate total tokens\n",
    "sample_size = 1000\n",
    "sample = text_sequence[:sample_size]\n",
    "tokens_per_char = len(tokenizer.encode(sample)) / len(sample)\n",
    "estimated_total = int(tokens_per_char * len(text_sequence))\n",
    "print(f\"Estimated total tokens: {estimated_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Create the directory structure\n",
    "save_dir = Path(\"model_llm/output/tokenizer\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save tokenizer\n",
    "with open(save_dir / \"my_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
